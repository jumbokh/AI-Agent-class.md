針對 **子專案二：跨模態影像特徵融合與高維嵌入結構研究**，我們可以將研究目標分解為具體的技術步驟與方法選擇，以下是依照研究流程進行的詳細技術探討：

---

## 🔍 子專案二詳解：技術步驟與理論基礎

---

### 🎯 **核心研究目標**

建立一個能將異質模態（如 RTI 成像與 3D 掃描）資料共同映射到**統一的嵌入特徵空間**中之方法，以利後續進行語義分析、關係判斷或修復建議等任務。該嵌入空間需滿足以下性質：

* **模態間對齊（Alignment）**
* **可分性（Separability）**
* **穩定性（Stability）**
* **幾何保持性（Geometric Preservation）**

---

## 🧪 技術步驟拆解與方法建議

---

### ✅ 步驟一：特徵提取與模態映射前處理

**任務：**
將 RTI 與 3D 掃描原始資料轉換為可學習的特徵形式。

**方法：**

* RTI：提取**紋理梯度、局部照明變化曲面、法線近似**
* 3D：提取**表面法線、局部曲率、深度圖**

**模型工具：**

* CNN（ResNet、MobileNet）提取 2D 紋理特徵
* PointNet、PointNet++ 或 MeshCNN 處理 3D 資料
* 將點雲投影成深度圖 → 統一為影像格式以利融合

---

### ✅ 步驟二：構建跨模態聯合嵌入空間

**任務：**
使異質資料在同一空間中表示，支持跨模態對齊與相似性度量。

**方法選項：**

* **聯合編碼器（Joint Encoder）**：
  同時輸入 RTI 和 3D 特徵，學習共享表示（shared embedding）

* **對比學習（Contrastive / Siamese Networks）**：
  拉近同一位置的 RTI 與 3D 特徵，推遠不同位置樣本

* **自監督對齊學習**：
  利用資料增強（如遮擋、旋轉）生成正負對，進行跨模態對比訓練（SimCLR、BYOL 風格）

**損失函數設計：**

* Triplet loss:
$$
    L = \\max(0, \\|f_a - f_p\\|^2 - \\|f_a - f_n\\|^2 + \\alpha)
$$
* Contrastive loss:
$$
    L = y \\cdot \\|f_1 - f_2\\|^2 + (1 - y) \\cdot \\max(0, m - \\|f_1 - f_2\\|)^2
$$
---

### ✅ 步驟三：高維結構分析與可分性評估

**任務：**
評估嵌入空間的品質，分析是否保留原始結構與語義信息。

**方法：**

* **流形保持性（Geometric preservation）**

* 使用 Isomap / t-SNE / UMAP 對嵌入進行可視化，觀察流形扭曲情形
* **Cluster separability 指標**（Silhouette Score, Davies-Bouldin Index）
* **穩定性測試**：多次隨機初始化與訓練，分析嵌入空間擾動情形

---

### ✅ 步驟四：跨模態特徵融合應用測試

**任務：**
將聯合特徵應用於分類、檢索或修復預測等任務，驗證嵌入空間實用性。

**可能應用：**

* 文物類型分類（RTI + 幾何）
* 缺陷位置預測（結構 + 紋理）
* 多模態檢索（輸入影像 → 找到對應 3D 結構）

**評估指標：**

* Accuracy / F1 score
* 檢索精度（Recall\@K）
* 嵌入相似性度量分布圖

---

## 🧩 小結：技術模組與對應工具一覽

| 階段   | 技術方法                            | 可能工具/模型                     |
| ---- | ------------------------------- | --------------------------- |
| 特徵提取 | CNN / PointNet                  | ResNet, PointNet++, MeshCNN |
| 嵌入學習 | 聯合編碼器 / 對比學習                    | SimCLR, BYOL, Siamese Net   |
| 結構分析 | t-SNE / UMAP / Silhouette       | sklearn, umap-learn         |
| 評估   | Triplet loss / Contrastive loss | PyTorch, TensorFlow         |

---



